{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install kaggle tensorboard wget\n",
    "! pip install tensorboard --upgrade\n",
    "! tensorboard --logdir=runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download -d gverzea/edible-wild-plants\n",
    "! unzip /content/edible-wild-plants.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/alexfrst/data-augmentation-benchmark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda:0 \u001B[92m✓\u001B[0m\n",
      "Loading dataset...\n",
      "Nombre d'images de train : 5902\n",
      "Nombre d'images de val : 656\n",
      "Nombre d'images de test : 310\n",
      "Apprentissage sur 62 classes\n",
      "Data loading and integrity check done \u001B[92m✓\u001B[0m\n",
      "Apprentissage en transfer learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 11it [02:35, 13.21s/it, Acc (val)=0.161, loss train=5.42, loss val=3.81]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"data-augmentation-benchmark\")\n",
    "\n",
    "import model.model as model\n",
    "from torch.optim import lr_scheduler\n",
    "from model.evaluate import evaluate\n",
    "from model.train import train_model\n",
    "from utils.dataset import load_dataset\n",
    "from utils.print_utils import Symbols\n",
    "from utils.tensorboard import tb_writer\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Working on {device} {Symbols.OK}\")\n",
    "\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=128)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inception_v3 = model.load_inception(nb_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = model.get_params_tranfer_learning(inception_v3, transfer_learning=True)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5, min_lr=1e-5)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en transfer learning avec inception\")\n",
    "inception_v3.to(device)\n",
    "inception_v3.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(inception_v3, train_loader, val_loader, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"inception_v3_tl\")\n",
    "inception_v3.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "inception_v3 = model.load_inception(nb_classes, transfer_learning=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(inception_v3.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5, min_lr=1e-5)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en fine tunning avec inception\")\n",
    "inception_v3.to(device)\n",
    "inception_v3.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(inception_v3, train_loader, val_loader, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"inception_v3_ft\")\n",
    "inception_v3.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "mobilenet = model.load_mobilenet(nb_classes, transfer_learning=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = model.get_params_tranfer_learning(mobilenet)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5, min_lr=1e-5)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en transfer learning avec mobilenet\")\n",
    "mobilenet.to(device)\n",
    "mobilenet.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(mobilenet, train_loader, val_loader, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"mobilenet_tl\")\n",
    "mobilenet.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mobilenet = model.load_mobilenet(nb_classes, transfer_learning=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(mobilenet.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5, min_lr=1e-5)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en fine tunning avec mobilenet\")\n",
    "mobilenet.to(device)\n",
    "mobilenet.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(mobilenet, train_loader, val_loader, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"mobilenet_ft\")\n",
    "mobilenet.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir runs --name \"My latest experiment\"  --description \"Simple comparison of several hyperparameters\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}