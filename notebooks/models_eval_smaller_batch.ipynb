{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu111 --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install kaggle tensorboard wget\n",
    "! pip install tensorboard --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download -d gverzea/edible-wild-plants\n",
    "! unzip /content/edible-wild-plants.zip -q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/alexfrst/data-augmentation-benchmark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda:0 \u001B[92m✓\u001B[0m\n",
      "Loading dataset...\n",
      "Nombre d'images de train : 5902\n",
      "Nombre d'images de val : 656\n",
      "Nombre d'images de test : 310\n",
      "Apprentissage sur 62 classes\n",
      "Data loading and integrity check done \u001B[92m✓\u001B[0m\n",
      "Apprentissage en transfer learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 11it [02:35, 13.21s/it, Acc (val)=0.161, loss train=5.42, loss val=3.81]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(\"data-augmentation-benchmark\")\n",
    "\n",
    "import model.model as model\n",
    "from torch.optim import lr_scheduler\n",
    "from model.evaluate import evaluate\n",
    "from model.train import train_model\n",
    "from utils.dataset import load_dataset\n",
    "from utils.print_utils import Symbols\n",
    "from utils.tensorboard import tb_writer\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Working on {device} {Symbols.OK}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "inception_v3 = model.load_inception(nb_classes, transfer_learning=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = model.get_params_tranfer_learning(inception_v3)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en transfer learning avec inception\")\n",
    "inception_v3.to(device)\n",
    "inception_v3.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(inception_v3, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"inception_v3_tl\")\n",
    "inception_v3.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "inception_v3 = model.load_inception(nb_classes, transfer_learning=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(inception_v3.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en fine tunning avec inception\")\n",
    "inception_v3.to(device)\n",
    "inception_v3.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(inception_v3, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"inception_v3_ft\")\n",
    "inception_v3.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "mobilenet = model.load_mobilenet(nb_classes, transfer_learning=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = model.get_params_tranfer_learning(mobilenet)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en transfer learning avec mobilenet\")\n",
    "mobilenet.to(device)\n",
    "mobilenet.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(mobilenet, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"mobilenet_tl\")\n",
    "mobilenet.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mobilenet = model.load_mobilenet(nb_classes, transfer_learning=False)\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(mobilenet.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en fine tunning avec mobilenet\")\n",
    "mobilenet.to(device)\n",
    "mobilenet.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(mobilenet, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"mobilenet_ft\")\n",
    "mobilenet.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "resnext = model.load_resnext(nb_classes, transfer_learning=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = model.get_params_tranfer_learning(resnext)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en transfer learning avec resnext\")\n",
    "resnext.to(device)\n",
    "resnext.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(resnext, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"resnext_tl\")\n",
    "resnext.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnext = model.load_resnext(nb_classes, transfer_learning=False)\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(resnext.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en fine tunning avec resnext\")\n",
    "resnext.to(device)\n",
    "resnext.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(resnext, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"resnext_ft\")\n",
    "resnext.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "convnext_small = model.load_convnext_small(nb_classes, transfer_learning=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = model.get_params_tranfer_learning(convnext_small)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en transfer learning avec convnext_small\")\n",
    "convnext_small.to(device)\n",
    "convnext_small.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(convnext_small, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"convnext_small_tl\")\n",
    "convnext_small.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "convnext_small = model.load_convnext_small(nb_classes, transfer_learning=False)\n",
    "train_loader, val_loader, test_loader, nb_classes = load_dataset(\"datasets/dataset\", \"datasets/dataset-test\", batch_size=6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(convnext_small.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "\n",
    "print(\"Apprentissage en fine tunning avec convnext_small\")\n",
    "convnext_small.to(device)\n",
    "convnext_small.train(True)\n",
    "\n",
    "best_model, best_val_score =  train_model(convnext_small, train_loader, val_loader, optimizer, scheduler, criterion, evaluate, 65, device=device, tb_writer=tb_writer, training_name=\"convnext_small_ft\")\n",
    "convnext_small.train(False)\n",
    "loss, accuracy = evaluate(best_model, test_loader, device, criterion)\n",
    "\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}